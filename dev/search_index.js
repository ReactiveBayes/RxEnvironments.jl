var documenterSearchIndex = {"docs":
[{"location":"lib/getting_started/#lib-started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"When using RxEnvironments, you only have to specify the dynamics of your environment. Let's create the Bayesian Thermostat environment in RxEnvironments. For this example, you need Distributions.jl installed in your environment as well. ","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's create the basics of our environment:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"using RxEnvironments\nusing Distributions\n\n# Empty agent, could contain states as well\nstruct ThermostatAgent end\n\nmutable struct BayesianThermostat\n    temperature::Real\n    min_temp::Real\n    max_temp::Real\nend\n\n# Helper functions\ntemperature(env::BayesianThermostat) = env.temperature\nmin_temp(env::BayesianThermostat) = env.min_temp\nmax_temp(env::BayesianThermostat) = env.max_temp\nnoise(env::BayesianThermostat) = Normal(0.0, 0.1)\nset_temperature!(env::BayesianThermostat, temp::Real) = env.temperature = temp\nfunction add_temperature!(env::BayesianThermostat, diff::Real) \n    env.temperature += diff\n    if temperature(env) < min_temp(env)\n        set_temperature!(env, min_temp(env))\n    elseif temperature(env) > max_temp(env)\n        set_temperature!(env, max_temp(env))\n    end\nend","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"By implementing RxEnvironments.receive!, RxEnvironments.send! and RxEnvironments.update! for our environment, we can fully specify the behaviour of our environment, and RxEnvironments will take care of the rest. In order to follow along with the sanity checks, please install Rocket.jl as well. The RxEnvironments.receive! and RxEnvironments.send! functions have a specific signature: RxEnvironments.receive!(receiver, emitter, action) takes as arguments the recipient of the action (in this example the environment), the emitter of the action (in this example the agent) and the action itself (in this example the change in temperature). The receive! function thus specifiec how an action from emitter to recipient affects the state of recipient. Always make sure to dispatch on the types of your environments, agents and actions, as RxEnvironments relies on Julia's multiple dispatch system to call the correct functions. Similarly for send!, which takes the recipient and emitter as arguments, that computes the observation from emitter presented to recipient. In our Bayesian Thermostat example, these functions look as follows:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"# When the environment receives an action from the agent, we add the value of the action to the environment temperature.\nRxEnvironments.receive!(recipient::BayesianThermostat, emitter::ThermostatAgent, action::Float64) = add_temperature!(recipient, action)\n\n# The environment sends a noisy observation of the temperature to the agent.\nRxEnvironments.send!(recipient::ThermostatAgent, emitter::BayesianThermostat) = temperature(emitter) + rand(noise(emitter))\n\n# The environment cools down over time.\nRxEnvironments.update!(env::BayesianThermostat, elapsed_time)= add_temperature!(env, -0.1 * elapsed_time)","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we've fully specified our environment, and we can interact with it. In order to create the environment, we use the RxEnvironment struct, and we add an agent to this environment using add!:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10, 10))\nagent = add!(environment, ThermostatAgent())","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we can have the agent conduct actions in our environment. Let's have the agent conduct some actions, and inspect the observations that are being returned by the environment:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"using Rocket\n\n# Subscribe a logger actor to the observations of the agent\nRxEnvironments.subscribe_to_observations!(agent, logger())\n\n# Conduct 10 actions:\nfor i in 1:10\n    action = rand()\n    RxEnvironments.conduct_action!(agent, environment, action)\n    sleep(1/5)\nend","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"[LogActor] Data: 0.006170718477015863\n[LogActor] Data: -0.09624863445330185\n[LogActor] Data: -0.3269267933074502\n[LogActor] Data: 0.001304207094952492\n[LogActor] Data: 0.03626599314271475\n[LogActor] Data: 0.010733164205412482\n[LogActor] Data: 0.12313893922057219\n[LogActor] Data: -0.013042652548091921\n[LogActor] Data: 0.03561033321842316\n[LogActor] Data: 0.6763921880509323\n[LogActor] Data: 0.8313618838112217\n[LogActor] Data: 1.7408316683602163\n[LogActor] Data: 1.7322639115928715\n[LogActor] Data: 1.458556241545732\n[LogActor] Data: 1.6689296645689367\n[LogActor] Data: 1.683300152848493\n[LogActor] Data: 2.087509970813057\n[LogActor] Data: 2.258940017058188\n[LogActor] Data: 2.6537100822978372\n[LogActor] Data: 2.6012179767058408\n[LogActor] Data: 3.0775745739101716\n[LogActor] Data: 2.7326464283572727","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Congratulations! You've now implemented a basic environment in RxEnvironments.","category":"page"},{"location":"lib/advanced_usage/#lib-advanced-examples","page":"Advanced Usage","title":"Advanced Usage","text":"","category":"section"},{"location":"lib/advanced_usage/#Changing-the-emission-rate-and-environment-speed","page":"Advanced Usage","title":"Changing the emission rate and environment speed","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By default, any RxEnvironment emits an observation to any subscribed agents every 1000 milliseconds, or whenever any agent in the environment conducts an action. To change this, one can use the emit_every_ms keyword argument to the RxEnvironment function. Taking the environment from the example:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10, 10); emit_every_ms = 10)","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Will emit an observation to any agents in the environment every 10 milliseconds.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By adjusting the real_time_factor keyword argument to the RxEnvironment function, one can play with the amount of computation time we give to agents to conduct their actions. For example:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10, 10); emit_every_ms = 1000, real_time_factor=2)","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Will emit an observation to every subscribed agent every 1000 milliseconds. However, the environment will only have moved 500 milliseconds forward, giving any subscribed agent twice as much time to choose an action than that it would have in a real-time setting.","category":"page"},{"location":"lib/advanced_usage/#Discrete-Environments","page":"Advanced Usage","title":"Discrete Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"RxEnvironments natively represents any environment as a continuous environment. However, discrete environments are also supported. By including the keyword argument discrete=true to the RxEnvironment function, we convert the environment to a discrete environment. There are 2 major differences between a discrete RxEnvironment and a continuous one:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"A discrete environment waits until all agents in the environment have conducted an action, and only then takes the last action emitted by every agent into account. I.e. if we have an environment with agent_1 and agent_2 as agents. If agent_1 emits two actions before agent_2 emits, the environment will only incorporate the second action emitted by agent_1 whenever agent_2 emits.\nA discrete environment needs to implement update!(::EnvironmentType), without the elapsed_time argument, since the state-transition does not depend on the elapsed time.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Tip: by implementing update!(::Environment) = update!(::Environment, dt) for a constant dt, a custom environment can be initialized both as a continuous as a discrete environment.","category":"page"},{"location":"lib/advanced_usage/#Animating-Environments","page":"Advanced Usage","title":"Animating Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Animating an environment is done using the GLMakie package. In order to animate your custom environments, please implement RxEnvironments.plot_state(ax, ::EnvironmentType), where ax is the GLMakie axis object that you can plot towards. If you need access to other agents or entities in order to plot your environments, you can extend RxEnvironments.add_to_state!(::EnvironmentType, ::AgentType) to make sure you have access to subscribed agents in the state.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By calling RxEnvironments.animate_state(::RxEnvironment; fps), RxEnvironments animates the plots you generate in the plot_state function to accurately reflect the state of your environment in real time.","category":"page"},{"location":"lib/advanced_usage/#Multi-Agent-Environments","page":"Advanced Usage","title":"Multi-Agent Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"RxEnvironments natively supports multi-agent environments, similarly to how we call add!(environment, agent) in the example page, we can call add! with additional agents in order to create a multi-agent environment. ","category":"page"},{"location":"lib/advanced_usage/#Inspecting-Observations","page":"Advanced Usage","title":"Inspecting Observations","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By using RxEnvironments.subscribe_to_observations! we can subscribe any Rocket actor to the observations of any entity. Note that these observations will be of type Observation, that also contains a reference to the entity that emitted the observation. In order to retrieve the value of the observation, you can call RxEnvironments.data on the Observation instance.","category":"page"},{"location":"lib/philosophy/#lib-design-philosophy","page":"Design Philosophy","title":"Design Philosophy","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"RxEnvironments is designed with Active Inference in mind. The philosophy behind Active Inference is different from classical control or reinforcement learning, and may even seem confusing if one is well-versed in either control or reinforcement learning. However, as explained on this page, the Active Inference philosophy gives us many advantages by design, such as multi-agent environments, compositional environments and nested environments. This page aims to clarify the design principles of RxEnvironments. ","category":"page"},{"location":"lib/philosophy/#Agent-Environment-interaction","page":"Design Philosophy","title":"Agent-Environment interaction","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"Classical reinforcement learning literature often makes the explicit distinction between an agent and the environment in which it lives. The interaction between agents and environments flows through the Markov Blanket of the agent; the agent emits actions and receives sensory observations. Similarly, the environment receives actions and emits observations to the agent. This symmetry of the Markov Blanket of both the agent and environment is crucial to notice: The actions of the agent are the observations of the environment, and vice versa. Consequently, one can argue that the environment is also an agent, which communicates to the agent through its Markov Blanket.","category":"page"},{"location":"lib/philosophy/#Entities-and-Markov-Blankets","page":"Design Philosophy","title":"Entities and Markov Blankets","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"The observation in the previous paragraph calls for an overarching term for both agents and environments. RxEnvironments realizes this with the AbstractEntity type. An entity is anything that has a Markov Blanket and can therefore communicate with other entities. Both agents and environments are AbstractEntity's under the hood. The difference is that an environment should implement the update! function to encode the state transition, whereas in agents this should be replaced by an inference process that selects an action to perform. We do not explicitly funnel rewards back from environments to agents, instead, agents should interpret the observations it receives and attach value to them instead.","category":"page"},{"location":"lib/philosophy/#The-power-of-Markov-Blankets","page":"Design Philosophy","title":"The power of Markov Blankets","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"All logic of RxEnvironments is written on the Entity level, this means that all logic holds for both agents and environments. For example: The fact that we support multi-agent environments also implies that an agent could emit actions to multiple environments as well, or that an agent can communicate with other agents in the same environment through its Markov Blanket. The concept of an Entity is what makes RxEnvironments so powerful and versatile. ","category":"page"},{"location":"lib/api_reference/#lib-api-reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"lib/api_reference/","page":"API Reference","title":"API Reference","text":"add!\nAbstractEntity\nterminate!\nis_subscribed\nupdate!\nsend!\nreceive!","category":"page"},{"location":"lib/api_reference/#RxEnvironments.add!","page":"API Reference","title":"RxEnvironments.add!","text":"add!(first::AbstractEntity{T,S,E}, second; environment=false) where {T,S,E}\n\nAdds second to first. If environment is true, the AbstractEntity created for second will be labeled as an environment.  The Markov Blankets for both entities will be subscribed to each other.\n\nArguments\n\nfirst::AbstractEntity{T,S,E}: The entity to which second will be added.\nsecond: The entity to be added to first.\nenvironment=false: A boolean indicating whether second should be instantiated as an environment.\n\n\n\n\n\n","category":"function"},{"location":"lib/api_reference/#RxEnvironments.AbstractEntity","page":"API Reference","title":"RxEnvironments.AbstractEntity","text":"AbstractEntity{T}\n\nThe AbstractEntity type supertypes all entities. It describes basic functionality all entities should have. It is assumed that every  entity has a markov blanket, which has actuators and sensors. The AbstractEntity also has a field that describes whether or not the entity is terminated. \n\n\n\n\n\n","category":"type"},{"location":"lib/api_reference/#RxEnvironments.terminate!","page":"API Reference","title":"RxEnvironments.terminate!","text":"terminate!(entity::AbstractEntity)\n\nTerminate an entity by setting its is_terminated flag to true and severing off all subscriptions to and from the entity.\n\nArguments\n\nentity::AbstractEntity: The entity to terminate.\n\n\n\n\n\n","category":"function"},{"location":"lib/api_reference/#RxEnvironments.is_subscribed","page":"API Reference","title":"RxEnvironments.is_subscribed","text":"is_subscribed(subject::AbstractEntity, target::AbstractEntity)\n\nCheck if subject is subscribed to target.\n\nArguments\n\nsubject::AbstractEntity: The entity that may be subscribed to target.\ntarget::AbstractEntity: The entity that may be subscribed to by subject.\n\nReturns\n\ntrue if subject is subscribed to target, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"lib/api_reference/#RxEnvironments.update!","page":"API Reference","title":"RxEnvironments.update!","text":"update!(e::AbstractEntity{T,ContinuousEntity,E}) where {T,E}\n\nUpdate the state of the entity e based on its current state and the time elapsed since the last update. Acts as state transition function.\n\nArguments\n\ne::AbstractEntity{T,ContinuousEntity,E}: The entity to update.\n\n\n\n\n\n","category":"function"},{"location":"lib/api_reference/#RxEnvironments.send!","page":"API Reference","title":"RxEnvironments.send!","text":"send!(recipient::AbstractEntity, emitter::AbstractEntity, action::Any)\n\nSend an action from emitter to recipient.\n\n\n\n\n\nsend!(recipient::AbstractEntity, emitter::AbstractEntity)\n\nSend an action from emitter to recipient. Should use the state of emitter to determine the action to send.\n\nSee also: RxEnvironments.receive!\n\n\n\n\n\n","category":"function"},{"location":"lib/api_reference/#RxEnvironments.receive!","page":"API Reference","title":"RxEnvironments.receive!","text":"receive!(recipient::AbstractEntity, emitter::AbstractEntity, observation::Any)\n\nReceive an observation from emitter and update the state of recipient accordingly.\n\nSee also: RxEnvironments.send!\n\n\n\n\n\n","category":"function"},{"location":"#RxEnvironments.jl-Documentation","page":"Introduction","title":"RxEnvironments.jl Documentation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Welcome to the documentation for RxEnvironments.jl! This document provides an overview of the package's functionality and usage.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"To install RxEnvironments.jl, use the following Julia command:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"RxEnvironments\")","category":"page"},{"location":"#Table-of-Contents","page":"Introduction","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n  \"lib/getting_started.md\",\n  \"lib/example_mountaincar.md\",\n  \"lib/advanced_usage.md\",\n  \"lib/philosophy.md\",\n  \"lib/api_reference.md\",\n]\nDepth = 2","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"lib/example_mountaincar/#lib-mountain-car","page":"Example: Mountain Car","title":"Example: Mountain Car Environment","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"On this page we will work out a more advanced example of an environment in RxEnvironments. The code on this page is the implementation of the Mountain Car environment in the core of the package. ","category":"page"},{"location":"lib/example_mountaincar/#Environment-details","page":"Example: Mountain Car","title":"Environment details","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The mountain car environment is a classical environment that first appeared in Andrew Moore's PhD thesis, where a car is placed in the valley of a mountainous landscape. The car can apply accelerations to its position, and the goal is to get the car up the hills adjacent to the valley. However, the engine power of the car alone is not enough to get out of the valley, and thus the agents in the environment should figure out that it can use the additional speed gained from driving up and down the hill on the other side to get to the desired location. The agent therefore can conduct action a in -1 1 to change the direction and intensity of the engine force.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"There are several forces that work on the car, namely:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Gravitational force from the slope of the landscape.\nFriction force from movement.\nThe power exerted by the engine of the car.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The gravitational force can be computed as follows, here m is the mass of the car, l(x) the landscape function as function of horizontal position x:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":" F_g(x m l) = -981 cdot m cdot left( sin arctan fracdldx(x)right)\n \n\nThe friction force is linear in the velocity v and the friction coefficient c_f of the car","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"math Ff(v, cf) = - v \\cdot c_f","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nThe engine power is a direct effect of action $a$, and is scaled by constant engine power $c_e$:\n","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"math Fe(a, ce) = a \\cdot c_e","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\n## RxEnvironments design pattern\nThe environment details explained above describe a set of differential equations governing the location and velocity of the car. In [classical implementations](https://mgoulao.github.io/gym-docs/environments/classic_control/mountain_car_continuous/) of the mountain car environment, the timestep is fixed and the differential equation is solved with the [Euler method](https://en.wikipedia.org/wiki/Euler_method). However, in `RxEnvironments` we have continuous time environments that are realized by varying the timestep between environment state updates. Therefore, using Euler's method to solve the system of differential equations accumulates errors in every timestep, and running the same environment twice might give us different realizations of the environment dynamics because of the way the errors are accumulated with varying timesteps between state updates. \n\nIn order to still get consistent simulations, the following design pattern may be of use when building an environment in `RxEnvironments`, and we will also employ this design pattern when implementing the Mountain Car environment: We use the `DifferentialEquations.jl` package to determine the trajectory of a moving object over a longer period of time and save this in the state of the object. Then, whenever we have to do a state update, we first determine whether or not the trajectory is still valid (for example, there were no collisions or actions conducted that change the trajectory of the object). If the trajectory is still valid, we simply return the desired value from the precomputed trajectory. If the trajectory is not valid anymore, we recompute the trajectory with the updated state of the object and save the new trajectory in the state of the object. In this way, we obtain a consistent and accurate state update irrespective of the varying timestep size of the state updates.\n## Implementing the environment\nNow that we've specified the environment dynamics and the design pattern for getting accurate state updates, it is time to implement the environment in `RxEnvironments`.\n### Setup\nFor this environment we have some specific requirements, please make sure these are installed. Furthermore, we define a generic landscape function to utilize, but the environment will also work with other (differentiable) landscape functions.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia import HypergeometricFunctions: _₂F₁ using Distributions using ForwardDiff using DifferentialEquations using LinearAlgebra using RxEnvironments","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function landscape(x)     if x < 0         h = x^2 + x     else         h =             x * _₂F₁(0.5, 0.5, 1.5, -5 * x^2) +             x^3 * _₂F₁(1.5, 1.5, 2.5, -5 * x^2) / 3 +             x^5 / 80     end     return 0.05 * h end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"### Defining environment structures\nIn order to implement the design pattern described above, we need to create a structure in which we are going to store the precomputed trajectory of the mountain car:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"mutable struct MountainCarTrajectory     recompute::Bool     time_left::Real     trajectory::Any     T::Real end","category":"page"},{"location":"lib/example_mountaincar/#Convenient-getters-and-setters","page":"Example: Mountain Car","title":"Convenient getters and setters","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"recompute(trajectory::MountainCarTrajectory) = trajectory.recompute timeleft(trajectory::MountainCarTrajectory) = trajectory.timeleft currenttime(trajectory::MountainCarTrajectory) =     totaltime(trajectory) - timeleft(trajectory) totaltime(trajectory::MountainCarTrajectory) = trajectory.T Base.getindex(trajectory::MountainCarTrajectory, index) = trajectory.trajectory(index)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"setrecompute!(trajectory::MountainCarTrajectory, recompute) =     trajectory.recompute = recompute settimeleft!(trajectory::MountainCarTrajectory, timeleft) =     trajectory.timeleft = timeleft reducetimeleft!(trajectory::MountainCarTrajectory, elapsedtime) =     settimeleft!(trajectory, timeleft(trajectory) - elapsed_time)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Here, we also implement all helper functions that give us a convenient interface to work with this trajectory. This trajectory is wrapped in the state of a Mountain Car, which contains all variables of the mountain car that are subject to change, such as position and velocity.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"mutable struct MountainCarState     position::Real     velocity::Real     throttle::Real     trajectory::MountainCarTrajectory end","category":"page"},{"location":"lib/example_mountaincar/#Convenient-getters-and-setters-2","page":"Example: Mountain Car","title":"Convenient getters and setters","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"position(state::MountainCarState) = state.position velocity(state::MountainCarState) = state.velocity throttle(state::MountainCarState) = state.throttle observable_state(state::MountainCarState) = [position(state), velocity(state)]","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"setposition!(state::MountainCarState, position::Real) = state.position = position setvelocity!(state::MountainCarState, velocity::Real) = state.velocity = velocity setthrottle!(state::MountainCarState, throttle::Real) = state.throttle = throttle settrajectory!(state::MountainCarState, trajectory) = state.trajectory = trajectory trajectory(state::MountainCarState) = state.trajectory","category":"page"},{"location":"lib/example_mountaincar/#Convenient-constructor-that-creates-an-empty-trajectory-that-will-immediately-be-replaced.","page":"Example: Mountain Car","title":"Convenient constructor that creates an empty trajectory that will immediately be replaced.","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"MountainCarState(position::Real, velocity::Real, throttle::Real) = MountainCarState(     position,     velocity,     throttle,     MountainCarTrajectory(true, 0.0, [], 0.0), )","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nThe actual Mountain Car struct will contain the state of the mountain car, as well as constants such as the engine power and friction coefficient:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"struct MountainCarAgent     state::MountainCarState     enginepower::Real     frictioncoefficient::Real     mass::Real     target::Real end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"MountainCarAgent(     position::Real,     enginepower::Real,     frictioncoefficient::Real,     mass::Real,     target::Real, ) = MountainCarAgent(     MountainCarState(position, 0.0, 0.0),     enginepower,     frictioncoefficient,     mass,     target, )","category":"page"},{"location":"lib/example_mountaincar/#Convenient-getters-and-setters-3","page":"Example: Mountain Car","title":"Convenient getters and setters","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"state(car::MountainCarAgent) = car.state position(car::MountainCarAgent) = position(state(car)) velocity(car::MountainCarAgent) = velocity(state(car)) throttle(car::MountainCarAgent) = throttle(state(car)) mass(car::MountainCarAgent) = car.mass observablestate(car::MountainCarAgent) = observablestate(state(car))","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"setposition!(car::MountainCarAgent, position::Real) = setposition!(state(car), position) setvelocity!(car::MountainCarAgent, velocity::Real) = setvelocity!(state(car), velocity) setthrottle!(car::MountainCarAgent, throttle::Real) = setthrottle!(state(car), throttle) enginepower(car::MountainCarAgent) = car.enginepower frictioncoefficient(car::MountainCarAgent) = car.frictioncoefficient settrajectory!(car::MountainCarAgent, trajectory) = settrajectory!(state(car), trajectory) trajectory(car::MountainCarAgent) = trajectory(state(car))","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nNow we are in a shape where we can define the actual environment, which will contain a landscape function and a collection of Mountain Cars:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia struct MountainCarEnvironment     actors::Vector{MountainCarAgent}     landscape::Any end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"MountainCarEnvironment(landscape) = MountainCarEnvironment([], landscape)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nIn order to encode the actions conducted by mountain car entities on the environment, we introduce a `Throttle` struct that clamps an input action between $-1$ and $1$:\n","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia struct Throttle     throttle::Real     Throttle(throttle::Real) = new(clamp(throttle, -1, 1)) end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Our environment contains a field `actors`, however, we still have to tell `RxEnvironments` how to add entities to this field:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia function RxEnvironments.addtostate!(environment::MountainCarEnvironment, agent::MountainCarAgent)     push!(environment.actors, agent) end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"### Environment dynamics\nWhen simulating the environment dynamics we need to be able to calculate all forces exerted on the car at any point in time:\n","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"throttle(action::Throttle) = action.throttle friction(car::MountainCarAgent, velocity) = velocity * -friction_coefficient(car) gravitation(car::MountainCarAgent, position, landscape) =     mass(car) * -9.81 * sin(atan(ForwardDiff.derivative(landscape, position)))","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\n### Solving the differential equations\nWe have set up the infrastructure with which we can save a trajectory of a moving object in its state, and retrieve this trajectory during future state updates. For this, we use the [`DifferentialEquations.jl`](https://docs.sciml.ai/DiffEqDocs/stable/) package, and we refer to the documentation of the `DifferentialEquations.jl` package for a more comprehensive explanation of solving differential equations in Julia. This section merely shows an example of the desired design pattern in `RxEnvironments.jl`. We have to compute the dynamics of the mountain car and save this in the state of the mountain car:","category":"page"},{"location":"lib/example_mountaincar/#DifferentialEquations.jl-function-describing-the-environment-dynamics.","page":"Example: Mountain Car","title":"DifferentialEquations.jl function describing the environment dynamics.","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function __mountaincardynamics(du, u, s, t)     agent, env = s     position, momentum = u     du[1] = momentum     du[2] =         throttle(agent) +         friction(agent, momentum) +         gravitation(agent, position, env.landscape) end","category":"page"},{"location":"lib/example_mountaincar/#Function-that-computes-a-trajectory-for-a-mountain-car-for-5-seconds-ahead-and-saves-this-result-in-the-state-of-the-corresponding-car.","page":"Example: Mountain Car","title":"Function that computes a trajectory for a mountain car for 5 seconds ahead and saves this result in the state of the corresponding car.","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function computemountaincardynamics(     agent::MountainCarAgent,     environment::MountainCarEnvironment, )     T = 5.0     initialstate = [position(agent), velocity(agent)]     tspan = (0.0, T)     prob = ODEProblem(mountaincardynamics, initialstate, tspan, (agent, environment))     sol = solve(prob, Tsit5())     settrajectory!(agent, MountainCarTrajectory(false, T, sol, T)) end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\n### Implementing `RxEnvironments` functions\nAll code we have written so far has served as setup for our environment, and we haven't written any core `RxEnvironments.jl` code yet. In this section we will write and elaborate on the necessary code to make our environment fully reactive. \n\n`RxEnvironments.jl` requires us to implement 3 functions specifically for our environment: `send!`, `receive!` and `update!`:\n`send!(recipient, emitter)` determines the message `emitter` sends to `recipient`. In our example, this function describes how the environment presents an observation to the agent, as function of the environment state.\n`receive!(recipient, emitter, observation)` determines how `observation` sent from `emitter` to `recipient` influences the internal state of `recipient`. In our example, this describes how a `Throttle` action from the agent changes the environment state.\n`update!(entity, elapsed_time)` describes the state transition of `entity` for `elapsed_time` if there are no incoming observations. In our example, this is how the environment gravity and friction influence the position and velocity of the agent inbetween agent actions.\nA notable detail is that, with our differential equations solution, we also have to check whenever we `update!` the environment if we have to recompute the trajectory for a mountain car, and whenever we `receive!` an action from an agent, that we should always recompute the trajectory.\n","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia ","category":"page"},{"location":"lib/example_mountaincar/#The-agent-observes-a-noisy-estimate-of-its-actual-position-and-velocity","page":"Example: Mountain Car","title":"The agent observes a noisy estimate of its actual position and velocity","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"RxEnvironments.send!(agent::MountainCarAgent, environment::MountainCarEnvironment) =     return rand(MvNormal(observable_state(agent), I(2)))","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function RxEnvironments.receive!(     environment::MountainCarEnvironment,     agent::MountainCarAgent,     action::Throttle, )     # We always have to recompute the trajecory of an agent if this agent conducts an action     setrecompute!(trajectory(agent), true)     setthrottle!(agent, throttle(action) * engine_power(agent)) end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function update!(environment::MountainCarEnvironment, elapsedtime::Real)     # Update all actors in the environment     for agent in environment.actors         # If we have conducted an action or the current trajecory is valid for less than `elapsedtime` seconds, recompute         if recompute(trajectory(agent)) || timeleft(trajectory(agent)) < elapsedtime             __computemountaincardynamics(agent, environment)         end         # Bookkeeping for the trajecory, position and velocity         reducetimeleft!(trajectory(agent), elapsedtime)         newstate = trajectory(agent)[currenttime(trajectory(agent))]         setposition!(agent, newstate[1])         setvelocity!(agent, newstate[2])     end end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nWith these funcitons we have specified the full environment behaviour, and the environment is now fully functional in `RxEnvironments.jl`. \nWe can create the environment with the `RxEnvironment` factory method:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia enginepower = 0.6 frictioncoefficient = 0.5 mass = 2 target = 1","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"env = RxEnvironment(MountainCarEnvironment(landscape)) agent = add!(             env,             MountainCarAgent(                 MountainCarState(-0.5, 0.0, 0.0),                 enginepower,                 frictioncoefficient,                 mass,                 target,             ),         )","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\n### Discrete-time Mountain Car\nClassical control theory mainly deals with discrete-time environments, and it is actually very easy to convert the environment dynamics we have written in `RxEnvironments` to also define a discrete environment. In general, the following design pattern is very helpful:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia update!(env::YourEnvironment) = update!(env, dt)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"for your choice of `dt`. For our mountain car environment, we can set the default timestep to $0.1$ as follows:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia update!(env::MountainCarEnvironment) = update!(env, 0.1)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"This will still utilize all environment dynamics we have written for the continuous case, but will create a discrete-time environment. In order to create a discrete-time environment, please make sure to include the `discrete=true` keyword argument for the `RxEnvironment` factory method:\n","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia enginepower = 0.6 frictioncoefficient = 0.5 mass = 2 target = 1","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"env = RxEnvironment(MountainCarEnvironment(landscape); discrete=true) agent = add!(             env,             MountainCarAgent(                 MountainCarState(-0.5, 0.0, 0.0),                 enginepower,                 frictioncoefficient,                 mass,                 target,             ),         )","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"### Animating the state of the environment\nIn order to animate the state of the environment, we have to install `GLMakie.jl` and implement the `plot_state` function for our environment.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia using GLMakie","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function RxEnvironments.plot_state(ax, environment::MountainCarEnvironment)     x = range(-2.5, 2.5, 100)     y = environment.landscape.(x)     lines!(ax, x, y)     for agent in environment.actors         position = position(agent)         scatter!(ax, position, environment.landscape(position))     end end","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nNow we can call:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"julia animatestate(env) ``on an existingRxEnvironmentwrapping theMountainCarEnvironment` and obtain a similar visualization: ![](../img/animatestate.png)","category":"page"}]
}
