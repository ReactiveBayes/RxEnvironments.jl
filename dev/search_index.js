var documenterSearchIndex = {"docs":
[{"location":"lib/getting_started/#lib-started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"When using RxEnvironments, you only have to specify the dynamics of your environment. Let's create the Bayesian Thermostat environment in RxEnvironments. For this example, you need Distributions.jl installed in your environment as well. ","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's create the basics of our environment:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"using RxEnvironments\nusing Distributions\n\n# Empty agent, could contain states as well\nstruct ThermostatAgent end\n\nmutable struct BayesianThermostat{T}\n    temperature::T\n    min_temp::T\n    max_temp::T\nend\n\n# Helper functions\ntemperature(env::BayesianThermostat) = env.temperature\nmin_temp(env::BayesianThermostat) = env.min_temp\nmax_temp(env::BayesianThermostat) = env.max_temp\nnoise(env::BayesianThermostat) = Normal(0.0, 0.1)\nset_temperature!(env::BayesianThermostat, temp::Real) = env.temperature = temp\nfunction add_temperature!(env::BayesianThermostat, diff::Real) \n    env.temperature += diff\n    if temperature(env) < min_temp(env)\n        set_temperature!(env, min_temp(env))\n    elseif temperature(env) > max_temp(env)\n        set_temperature!(env, max_temp(env))\n    end\nend","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"By implementing RxEnvironments.receive!, RxEnvironments.what_to_send and RxEnvironments.update! for our environment, we can fully specify the behaviour of our environment, and RxEnvironments will take care of the rest. The RxEnvironments.receive! and RxEnvironments.what_to_send functions have a specific signature: RxEnvironments.receive!(receiver, emitter, action) takes as arguments the recipient of the action (in this example the environment), the emitter of the action (in this example the agent) and the action itself (in this example the change in temperature). The receive! function thus specifiec how an action from emitter to recipient affects the state of recipient. Always make sure to dispatch on the types of your environments, agents and actions, as RxEnvironments relies on Julia's multiple dispatch system to call the correct functions. Similarly for what_to_send, which takes the recipient and emitter (and potentially observation) as arguments, that computes the observation from emitter presented to recipient (when emitter has received observation). In our Bayesian Thermostat example, these functions look as follows:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"# When the environment receives an action from the agent, we add the value of the action to the environment temperature.\nRxEnvironments.receive!(recipient::BayesianThermostat, emitter::ThermostatAgent, action::Real) = add_temperature!(recipient, action)\n\n# The environment sends a noisy observation of the temperature to the agent.\nRxEnvironments.what_to_send(recipient::ThermostatAgent, emitter::BayesianThermostat) = temperature(emitter) + rand(noise(emitter))\n\n# The environment cools down over time.\nRxEnvironments.update!(env::BayesianThermostat, elapsed_time)= add_temperature!(env, -0.1 * elapsed_time)","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we've fully specified our environment, and we can interact with it. In order to create the environment, we use the RxEnvironment struct, and we add an agent to this environment using add!:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10.0, 10.0); emit_every_ms = 900)\nagent = add!(environment, ThermostatAgent())","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Now we can have the agent conduct actions in our environment. Let's have the agent conduct some actions, and inspect the observations that are being returned by the environment:","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"# Subscribe a logger actor to the observations of the agent\nRxEnvironments.subscribe_to_observations!(agent, RxEnvironments.logger())\n\n# Conduct 10 actions:\nfor i in 1:10\n    action = rand()\n    RxEnvironments.send!(environment, agent, action)\n    sleep(1)\nend","category":"page"},{"location":"lib/getting_started/","page":"Getting Started","title":"Getting Started","text":"Congratulations! You've now implemented a basic environment in RxEnvironments.","category":"page"},{"location":"lib/advanced_usage/#lib-advanced-examples","page":"Advanced Usage","title":"Advanced Usage","text":"","category":"section"},{"location":"lib/advanced_usage/#Changing-the-emission-rate-and-environment-speed","page":"Advanced Usage","title":"Changing the emission rate and environment speed","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By default, any RxEnvironment emits an observation to any subscribed agents every 1000 milliseconds, or whenever any agent in the environment conducts an action. To change this, one can use the emit_every_ms keyword argument to the RxEnvironment function. Taking the environment from the example:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10, 10); emit_every_ms = 10)","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Will emit an observation to any agents in the environment every 10 milliseconds.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By adjusting the real_time_factor keyword argument to the RxEnvironment function, one can play with the amount of computation time we give to agents to conduct their actions. For example:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"environment = RxEnvironment(BayesianThermostat(0.0, -10, 10); emit_every_ms = 1000, real_time_factor=2)","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Will emit an observation to every subscribed agent every 1000 milliseconds. However, the environment will only have moved 500 milliseconds forward, giving any subscribed agent twice as much time to choose an action than that it would have in a real-time setting.","category":"page"},{"location":"lib/advanced_usage/#Discrete-Environments","page":"Advanced Usage","title":"Discrete Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"RxEnvironments natively represents any environment as a continuous environment. However, discrete environments are also supported. By including the keyword argument discrete=true to the RxEnvironment function, we convert the environment to a discrete environment. There are 2 major differences between a discrete RxEnvironment and a continuous one:","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"A discrete environment waits until all agents in the environment have conducted an action, and only then takes the last action emitted by every agent into account. I.e. if we have an environment with agent_1 and agent_2 as agents. If agent_1 emits two actions before agent_2 emits, the environment will only incorporate the second action emitted by agent_1 whenever agent_2 emits.\nA discrete environment has a fixed time between state transitions, which can be set by implementing RxEnvironments.time_interval(::YourEntityType). This function should return the time interval between state transitions in seconds, which by default is 1.0.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Note that by \"Discrete\", we mean that the environment is discrete in time, not in state space. The state space can still be continuous. Note, however, that for more complex entity interactions, the fact that a discrete entity waits for all subscribers to emit before transitioning to the next state can lead to undesired behavior.","category":"page"},{"location":"lib/advanced_usage/#Animating-Environments","page":"Advanced Usage","title":"Animating Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Animating an environment is done using the GLMakie package. In order to animate your custom environments, please implement RxEnvironments.plot_state(ax, ::EnvironmentType), where ax is the GLMakie axis object that you can plot towards. If you need access to other agents or entities in order to plot your environments, you can extend RxEnvironments.add_to_state!(::EnvironmentType, ::AgentType) to make sure you have access to subscribed agents in the state.","category":"page"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By calling RxEnvironments.animate_state(::RxEnvironment; fps), RxEnvironments animates the plots you generate in the plot_state function to accurately reflect the state of your environment in real time.","category":"page"},{"location":"lib/advanced_usage/#Multi-Agent-Environments","page":"Advanced Usage","title":"Multi-Agent Environments","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"RxEnvironments natively supports multi-agent environments, similarly to how we call add!(environment, agent) in the example page, we can call add! with additional agents in order to create a multi-agent environment. ","category":"page"},{"location":"lib/advanced_usage/#Inspecting-Observations","page":"Advanced Usage","title":"Inspecting Observations","text":"","category":"section"},{"location":"lib/advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"By using RxEnvironments.subscribe_to_observations! we can subscribe any Rocket actor to the observations of any entity. Note that these observations will be of type Observation, that also contains a reference to the entity that emitted the observation. In order to retrieve the value of the observation, you can call RxEnvironments.data on the Observation instance.","category":"page"},{"location":"lib/philosophy/#lib-design-philosophy","page":"Design Philosophy","title":"Design Philosophy","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"RxEnvironments is designed with Active Inference in mind. The philosophy behind Active Inference is different from classical control or reinforcement learning, and may even seem confusing if one is well-versed in either control or reinforcement learning. However, as explained on this page, the Active Inference philosophy gives us many advantages by design, such as multi-agent environments, compositional environments and nested environments. This page aims to clarify the design principles of RxEnvironments. ","category":"page"},{"location":"lib/philosophy/#Agent-Environment-interaction","page":"Design Philosophy","title":"Agent-Environment interaction","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"Classical reinforcement learning literature often makes the explicit distinction between an agent and the environment in which it lives. The interaction between agents and environments flows through the Markov Blanket of the agent; the agent emits actions and receives sensory observations. Similarly, the environment receives actions and emits observations to the agent. This symmetry of the Markov Blanket of both the agent and environment is crucial to notice: The actions of the agent are the observations of the environment, and vice versa. Consequently, one can argue that the environment is also an agent, which communicates to the agent through its Markov Blanket.","category":"page"},{"location":"lib/philosophy/#Entities-and-Markov-Blankets","page":"Design Philosophy","title":"Entities and Markov Blankets","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"The observation in the previous paragraph calls for an overarching term for both agents and environments. RxEnvironments realizes this with the AbstractEntity type. An entity is anything that has a Markov Blanket and can therefore communicate with other entities. Both agents and environments are AbstractEntity's under the hood. The difference is that an environment should implement the update! function to encode the state transition, whereas in agents this should be replaced by an inference process that selects an action to perform. We do not explicitly funnel rewards back from environments to agents, instead, agents should interpret the observations it receives and attach value to them instead.","category":"page"},{"location":"lib/philosophy/#The-power-of-Markov-Blankets","page":"Design Philosophy","title":"The power of Markov Blankets","text":"","category":"section"},{"location":"lib/philosophy/","page":"Design Philosophy","title":"Design Philosophy","text":"All logic of RxEnvironments is written on the Entity level, this means that all logic holds for both agents and environments. For example: The fact that we support multi-agent environments also implies that an agent could emit actions to multiple environments as well, or that an agent can communicate with other agents in the same environment through its Markov Blanket. The concept of an Entity is what makes RxEnvironments so powerful and versatile. ","category":"page"},{"location":"lib/api_reference/#lib-api-reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"lib/api_reference/","page":"API Reference","title":"API Reference","text":"Modules = [RxEnvironments]\nOrder   = [:type, :function]","category":"page"},{"location":"lib/api_reference/#RxEnvironments.AbstractEntity","page":"API Reference","title":"RxEnvironments.AbstractEntity","text":"AbstractEntity{T}\n\nThe AbstractEntity type supertypes all entities. It describes basic functionality all entities should have. It is assumed that every  entity has a markov blanket, which has actuators and sensors. The AbstractEntity also has a field that describes whether or not the entity is terminated. \n\n\n\n\n\n","category":"type"},{"location":"lib/api_reference/#RxEnvironments.RxEntity","page":"API Reference","title":"RxEnvironments.RxEntity","text":"RxEntity\n\nThe RxEntity is the vanilla implementation of an AbstractEntity that is used in most cases. It is a wrapper around an entity that adds the following functionality:\n\nA MarkovBlanket that contains the actuators and sensors of the entity\nA EntityProperties that contains the state space, whether or not the entity is active, and the real time factor\nA EntityActor that handles the logic for receiving observations and sending actions\n\n\n\n\n\n","category":"type"},{"location":"lib/api_reference/#Rocket.on_next!-Tuple{RxEnvironments.EntityActor{E} where E<:(AbstractEntity{T, S, <:RxEnvironments.ActiveEntity} where {T, S}), Any}","page":"API Reference","title":"Rocket.on_next!","text":"Rocket.on_next!(actor::EntityActor{ActiveEntity}, observation)})\n\nHandles the logic for an incoming observation for an active entity. This means that the entity will update its state, incorporate the observation into its state, and then send an action to all of its subscribers. The action is determined by the what_to_send function. Emissions can be filtered by implementing the emits function.\n\nThis function is automatically called whenever the entity receives an observation on it's sensor. The observation will contain the data sent by the emitter as well as a reference to the emitter itself. \n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#Rocket.on_next!-Tuple{RxEnvironments.EntityActor{E} where E<:(AbstractEntity{T, S, <:RxEnvironments.PassiveEntity} where {T, S}), Any}","page":"API Reference","title":"Rocket.on_next!","text":"Rocket.on_next!(actor::EntityActor{PassiveEntity}, observation)\n\nHandles the logic for an incoming observation for a passive entity. This means that we will only incorporate the observation into the entity's state.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#Rocket.unsubscribe!-Tuple{AbstractEntity, AbstractEntity}","page":"API Reference","title":"Rocket.unsubscribe!","text":"Unsubscribes receiver from emitter. Any data sent from emitter to receiver will not be received by receiver after this function is called.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.__send!-Tuple{Union{Rocket.Actor, AbstractEntity}, AbstractEntity, Any}","page":"API Reference","title":"RxEnvironments.__send!","text":"__send!(recipient::AbstractEntity, emitter::AbstractEntity, action::Any)\n\nSend an action from emitter to recipient.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.action_type-Tuple{Any}","page":"API Reference","title":"RxEnvironments.action_type","text":"action_type(::T)\n\nReturns the default action type for an entity of type T. By default, this function returns Any. This is used to determine the type of actions that can be sent to an entity. Although this restricts the type of actions that can be  sent to an entity, it allows for more type-stable code. \n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.add!-Union{Tuple{E}, Tuple{S}, Tuple{T}, Tuple{AbstractEntity{T, S, E}, Any}} where {T, S, E}","page":"API Reference","title":"RxEnvironments.add!","text":"add!(first::AbstractEntity{T,S,E}, second; environment=false) where {T,S,E}\n\nAdds second to first. If environment is true, the AbstractEntity created for second will be labeled as an environment.  The Markov Blankets for both entities will be subscribed to each other.\n\nArguments\n\nfirst::AbstractEntity{T,S,E}: The entity to which second will be added.\nsecond: The entity to be added to first.\nis_active=false: A boolean indicating whether second should be instantiated as an active entity.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.create_entity-Tuple{Any}","page":"API Reference","title":"RxEnvironments.create_entity","text":"create_entity(entity; is_discrete = false, is_active = false, real_time_factor = 1)\n\nCreates an RxEntity that decorates a given entity. The is_discrete and is_active parameters determine whether or not the entity lives in a discrete or continuous state-space, and whether or not the entity is active or passive. The real_time_factor parameter determines how fast the entity's clock ticks. This function can be used as a lower-level API in order to create a more complex network of entities.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.emits-Tuple{Any, Any, Any}","page":"API Reference","title":"RxEnvironments.emits","text":"emits(subject, listener, observation)\n\nDetermines if an entity of the type of subject should emit an observation to an entity of the type of listener when presented with an obervation of type observation. Users should implement this function for their own entity and observation types to handle the logic of when to emit observations to which entities. By default, this function returns true.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.is_subscribed-Tuple{AbstractEntity, AbstractEntity}","page":"API Reference","title":"RxEnvironments.is_subscribed","text":"is_subscribed(subject::AbstractEntity, target::AbstractEntity)\n\nCheck if subject is subscribed to target.\n\nArguments\n\nsubject::AbstractEntity: The entity that may be subscribed to target.\ntarget::AbstractEntity: The entity that may be subscribed to by subject.\n\nReturns\n\ntrue if subject is subscribed to target, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.receive!-Tuple{AbstractEntity, RxEnvironments.Observation}","page":"API Reference","title":"RxEnvironments.receive!","text":"receive!(recipient::AbstractEntity, emitter::AbstractEntity, observation::Any)\n\nReceive an observation from emitter and update the state of recipient accordingly.\n\nSee also: RxEnvironments.send!\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.send!-Tuple{Union{Rocket.Actor, AbstractEntity}, AbstractEntity, Any}","page":"API Reference","title":"RxEnvironments.send!","text":"send!(recipient::AbstractEntity, emitter::AbstractEntity, action::Any)\n\nSend an action from emitter to recipient.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.subscribe_to_observations!-Tuple{AbstractEntity, Any}","page":"API Reference","title":"RxEnvironments.subscribe_to_observations!","text":"subscribe_to_observations!(entity::AbstractEntity, actor)\n\nSubscribe actor to the observations of entity. Any data sent to entity will be received by actor after this function is called.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.terminate!-Tuple{AbstractEntity}","page":"API Reference","title":"RxEnvironments.terminate!","text":"terminate!(entity::AbstractEntity)\n\nTerminate an entity by setting its is_terminated flag to true and severing off all subscriptions to and from the entity.\n\nArguments\n\nentity::AbstractEntity: The entity to terminate.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.time_interval-Tuple{Any}","page":"API Reference","title":"RxEnvironments.time_interval","text":"time_interval(::T)\n\nReturns the default time interval for an entity of type T. By default, this function returns 1. This is used  in discrete active entities to determine the elapsed time between state updates. Through dispatching, we can  define different time intervals for different entity types.\n\n\n\n\n\n","category":"method"},{"location":"lib/api_reference/#RxEnvironments.update!-Union{Tuple{AbstractEntity{T, RxEnvironments.ContinuousEntity, E}}, Tuple{E}, Tuple{T}} where {T, E}","page":"API Reference","title":"RxEnvironments.update!","text":"update!(e::AbstractEntity{T,ContinuousEntity,E}) where {T,E}\n\nUpdate the state of the entity e based on its current state and the time elapsed since the last update. Acts as state transition function.\n\nArguments\n\ne::AbstractEntity{T,ContinuousEntity,E}: The entity to update.\n\n\n\n\n\n","category":"method"},{"location":"#RxEnvironments.jl-Documentation","page":"Introduction","title":"RxEnvironments.jl Documentation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Welcome to the documentation for RxEnvironments.jl! This document provides an overview of the package's functionality and usage.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"To install RxEnvironments.jl, use the following Julia command:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\nPkg.add(\"RxEnvironments\")","category":"page"},{"location":"#Table-of-Contents","page":"Introduction","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Pages = [\n  \"lib/getting_started.md\",\n  \"lib/example_mountaincar.md\",\n  \"lib/advanced_usage.md\",\n  \"lib/philosophy.md\",\n  \"lib/api_reference.md\",\n]\nDepth = 2","category":"page"},{"location":"#Index","page":"Introduction","title":"Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"lib/example_mountaincar/#lib-mountain-car","page":"Example: Mountain Car","title":"Example: Mountain Car Environment","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"On this page we will work out a more advanced example of an environment in RxEnvironments. The code on this page is the implementation of the Mountain Car environment in the core of the package. ","category":"page"},{"location":"lib/example_mountaincar/#Environment-details","page":"Example: Mountain Car","title":"Environment details","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The mountain car environment is a classical environment that first appeared in Andrew Moore's PhD thesis, where a car is placed in the valley of a mountainous landscape. The car can apply accelerations to its position, and the goal is to get the car up the hills adjacent to the valley. However, the engine power of the car alone is not enough to get out of the valley, and thus the agents in the environment should figure out that it can use the additional speed gained from driving up and down the hill on the other side to get to the desired location. The agent therefore can conduct action a in -1 1 to change the direction and intensity of the engine force.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"There are several forces that work on the car, namely:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Gravitational force from the slope of the landscape.\nFriction force from movement.\nThe power exerted by the engine of the car.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The gravitational force can be computed as follows, here m is the mass of the car, l(x) the landscape function as function of horizontal position x:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"F_g(x m l) = -981 cdot m cdot left( sin arctan fracdldx(x)right)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The friction force is linear in the velocity v and the friction coefficient c_f of the car:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"F_f(v c_f) = - v cdot c_f","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The engine power is a direct effect of action a, and is scaled by constant engine power c_e:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"F_e(a c_e) = a cdot c_e","category":"page"},{"location":"lib/example_mountaincar/#RxEnvironments-design-pattern","page":"Example: Mountain Car","title":"RxEnvironments design pattern","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The environment details explained above describe a set of differential equations governing the location and velocity of the car. In classical implementations of the mountain car environment, the timestep is fixed and the differential equation is solved with the Euler method. However, in RxEnvironments we have continuous time environments that are realized by varying the timestep between environment state updates. Therefore, using Euler's method to solve the system of differential equations accumulates errors in every timestep, and running the same environment twice might give us different realizations of the environment dynamics because of the way the errors are accumulated with varying timesteps between state updates. ","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"In order to still get consistent simulations, the following design pattern may be of use when building an environment in RxEnvironments, and we will also employ this design pattern when implementing the Mountain Car environment: We use the DifferentialEquations.jl package to determine the trajectory of a moving object over a longer period of time and save this in the state of the object. Then, whenever we have to do a state update, we first determine whether or not the trajectory is still valid (for example, there were no collisions or actions conducted that change the trajectory of the object). If the trajectory is still valid, we simply return the desired value from the precomputed trajectory. If the trajectory is not valid anymore, we recompute the trajectory with the updated state of the object and save the new trajectory in the state of the object. In this way, we obtain a consistent and accurate state update irrespective of the varying timestep size of the state updates.","category":"page"},{"location":"lib/example_mountaincar/#Implementing-the-environment","page":"Example: Mountain Car","title":"Implementing the environment","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Now that we've specified the environment dynamics and the design pattern for getting accurate state updates, it is time to implement the environment in RxEnvironments.","category":"page"},{"location":"lib/example_mountaincar/#Setup","page":"Example: Mountain Car","title":"Setup","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"For this environment we have some specific requirements, please make sure these are installed. Furthermore, we define a generic landscape function to utilize, but the environment will also work with other (differentiable) landscape functions.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"import HypergeometricFunctions: _₂F₁\nusing Distributions\nusing ForwardDiff\nusing DifferentialEquations\nusing LinearAlgebra\nusing RxEnvironments\n\nfunction landscape(x)\n    if x < 0\n        h = x^2 + x\n    else\n        h =\n            x * _₂F₁(0.5, 0.5, 1.5, -5 * x^2) +\n            x^3 * _₂F₁(1.5, 1.5, 2.5, -5 * x^2) / 3 +\n            x^5 / 80\n    end\n    return 0.05 * h\nend","category":"page"},{"location":"lib/example_mountaincar/#Defining-environment-structures","page":"Example: Mountain Car","title":"Defining environment structures","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"In order to implement the design pattern described above, we need to create a structure in which we are going to store the precomputed trajectory of the mountain car:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nmutable struct MountainCarTrajectory{T<:Real}\n    recompute::Bool\n    time_left::T\n    trajectory::Any\n    T::T\nend\n\n# Convenient getters and setters\nrecompute(trajectory::MountainCarTrajectory) = trajectory.recompute\ntime_left(trajectory::MountainCarTrajectory) = trajectory.time_left\ncurrent_time(trajectory::MountainCarTrajectory) =\n    total_time(trajectory) - time_left(trajectory)\ntotal_time(trajectory::MountainCarTrajectory) = trajectory.T\nBase.getindex(trajectory::MountainCarTrajectory, index) = trajectory.trajectory(index)\n\n\nset_recompute!(trajectory::MountainCarTrajectory, recompute) =\n    trajectory.recompute = recompute\nset_time_left!(trajectory::MountainCarTrajectory, time_left) =\n    trajectory.time_left = time_left\nreduce_time_left!(trajectory::MountainCarTrajectory, elapsed_time) =\n    set_time_left!(trajectory, time_left(trajectory) - elapsed_time)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Here, we also implement all helper functions that give us a convenient interface to work with this trajectory. This trajectory is wrapped in the state of a Mountain Car, which contains all variables of the mountain car that are subject to change, such as position and velocity.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\nmutable struct MountainCarState{T<:Real}\n    position::T\n    velocity::T\n    throttle::T\n    trajectory::MountainCarTrajectory{T}\nend\n\n# Convenient getters and setters\nposition(state::MountainCarState) = state.position\nvelocity(state::MountainCarState) = state.velocity\nthrottle(state::MountainCarState) = state.throttle\nobservable_state(state::MountainCarState) = [position(state), velocity(state)]\n\nset_position!(state::MountainCarState, position::Real) = state.position = position\nset_velocity!(state::MountainCarState, velocity::Real) = state.velocity = velocity\nset_throttle!(state::MountainCarState, throttle::Real) = state.throttle = throttle\nset_trajectory!(state::MountainCarState, trajectory) = state.trajectory = trajectory\ntrajectory(state::MountainCarState) = state.trajectory\n\n# Convenient constructor that creates an empty trajectory that will immediately be replaced.\nMountainCarState(position::Real, velocity::Real, throttle::Real) = MountainCarState(\n    position,\n    velocity,\n    throttle,\n    MountainCarTrajectory(true, 0.0, [], 0.0),\n)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"The actual Mountain Car struct will contain the state of the mountain car, as well as constants such as the engine power and friction coefficient:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"\n\nstruct MountainCarAgent{T<:Real}\n    state::MountainCarState{T}\n    engine_power::T\n    friction_coefficient::T\n    mass::T\n    target::T\nend\n\nMountainCarAgent(\n    position::Real,\n    engine_power::Real,\n    friction_coefficient::Real,\n    mass::Real,\n    target::Real,\n) = MountainCarAgent(\n    MountainCarState(position, 0.0, 0.0),\n    engine_power,\n    friction_coefficient,\n    mass,\n    target,\n)\n\n# Convenient getters and setters\nstate(car::MountainCarAgent) = car.state\nposition(car::MountainCarAgent) = position(state(car))\nvelocity(car::MountainCarAgent) = velocity(state(car))\nthrottle(car::MountainCarAgent) = throttle(state(car))\nmass(car::MountainCarAgent) = car.mass\nobservable_state(car::MountainCarAgent) = observable_state(state(car))\n\nset_position!(car::MountainCarAgent, position::Real) = set_position!(state(car), position)\nset_velocity!(car::MountainCarAgent, velocity::Real) = set_velocity!(state(car), velocity)\nset_throttle!(car::MountainCarAgent, throttle::Real) = set_throttle!(state(car), throttle)\nengine_power(car::MountainCarAgent) = car.engine_power\nfriction_coefficient(car::MountainCarAgent) = car.friction_coefficient\nset_trajectory!(car::MountainCarAgent, trajectory) = set_trajectory!(state(car), trajectory)\ntrajectory(car::MountainCarAgent) = trajectory(state(car))","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Now we are in a shape where we can define the actual environment, which will contain a landscape function and a collection of Mountain Cars:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"struct MountainCarEnvironment\n    actors::Vector{MountainCarAgent}\n    landscape::Any\nend\n\nMountainCarEnvironment(landscape) = MountainCarEnvironment([], landscape)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"In order to encode the actions conducted by mountain car entities on the environment, we introduce a Throttle struct that clamps an input action between -1 and 1:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"struct Throttle{T<:Real}\n    throttle::T\n    Throttle(throttle::T) where {T<:Real} = new{T}(clamp(throttle, -1, 1))\nend","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Our environment contains a field actors, however, we still have to tell RxEnvironments how to add entities to this field:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"function RxEnvironments.add_to_state!(environment::MountainCarEnvironment, agent::MountainCarAgent)\n    push!(environment.actors, agent)\nend","category":"page"},{"location":"lib/example_mountaincar/#Environment-dynamics","page":"Example: Mountain Car","title":"Environment dynamics","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"When simulating the environment dynamics we need to be able to calculate all forces exerted on the car at any point in time:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"throttle(action::Throttle) = action.throttle\nfriction(car::MountainCarAgent, velocity) = velocity * -friction_coefficient(car)\ngravitation(car::MountainCarAgent, position, landscape) =\n    mass(car) * -9.81 * sin(atan(ForwardDiff.derivative(landscape, position)))","category":"page"},{"location":"lib/example_mountaincar/#Solving-the-differential-equations","page":"Example: Mountain Car","title":"Solving the differential equations","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"We have set up the infrastructure with which we can save a trajectory of a moving object in its state, and retrieve this trajectory during future state updates. For this, we use the DifferentialEquations.jl package, and we refer to the documentation of the DifferentialEquations.jl package for a more comprehensive explanation of solving differential equations in Julia. This section merely shows an example of the desired design pattern in RxEnvironments.jl. We have to compute the dynamics of the mountain car and save this in the state of the mountain car:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"# DifferentialEquations.jl function describing the environment dynamics.\nfunction __mountain_car_dynamics(du, u, s, t)\n    agent, env = s\n    position, momentum = u\n    du[1] = momentum\n    du[2] =\n        throttle(agent) +\n        friction(agent, momentum) +\n        gravitation(agent, position, env.landscape)\nend\n\n# Function that computes a trajectory for a mountain car for 5 seconds ahead and saves this result in the state of the corresponding car.\nfunction __compute_mountain_car_dynamics(\n    agent::MountainCarAgent,\n    environment::MountainCarEnvironment,\n)\n    T = 5.0\n    initial_state = [position(agent), velocity(agent)]\n    tspan = (0.0, T)\n    prob = ODEProblem(__mountain_car_dynamics, initial_state, tspan, (agent, environment))\n    sol = solve(prob, Tsit5())\n    set_trajectory!(agent, MountainCarTrajectory(false, T, sol, T))\nend","category":"page"},{"location":"lib/example_mountaincar/#Implementing-RxEnvironments-functions","page":"Example: Mountain Car","title":"Implementing RxEnvironments functions","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"All code we have written so far has served as setup for our environment, and we haven't written any core RxEnvironments.jl code yet. In this section we will write and elaborate on the necessary code to make our environment fully reactive. ","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"RxEnvironments.jl requires us to implement 3 functions specifically for our environment: what_to_send, receive! and update!: what_to_send(recipient, emitter) determines the message emitter sends to recipient. In our example, this function describes how the environment presents an observation to the agent, as function of the environment state. receive!(recipient, emitter, observation) determines how observation sent from emitter to recipient influences the internal state of recipient. In our example, this describes how a Throttle action from the agent changes the environment state. update!(entity, elapsed_time) describes the state transition of entity for elapsed_time if there are no incoming observations. In our example, this is how the environment gravity and friction influence the position and velocity of the agent inbetween agent actions. A notable detail is that, with our differential equations solution, we also have to check whenever we update! the environment if we have to recompute the trajectory for a mountain car, and whenever we receive! an action from an agent, that we should always recompute the trajectory.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"# The agent observes a noisy estimate of its actual position and velocity\nRxEnvironments.what_to_send(agent::MountainCarAgent, environment::MountainCarEnvironment) =\n    return rand(MvNormal(observable_state(agent), I(2)))\n\nfunction RxEnvironments.receive!(\n    environment::MountainCarEnvironment,\n    agent::MountainCarAgent,\n    action::Throttle,\n)\n    # We always have to recompute the trajecory of an agent if this agent conducts an action\n    set_recompute!(trajectory(agent), true)\n    set_throttle!(agent, throttle(action) * engine_power(agent))\nend\n\nfunction RxEnvironments.update!(environment::MountainCarEnvironment, elapsed_time::Real)\n    # Update all actors in the environment\n    for agent in environment.actors\n        # If we have conducted an action or the current trajecory is valid for less than `elapsed_time` seconds, recompute\n        if recompute(trajectory(agent)) || time_left(trajectory(agent)) < elapsed_time\n            __compute_mountain_car_dynamics(agent, environment)\n        end\n        # Bookkeeping for the trajecory, position and velocity\n        reduce_time_left!(trajectory(agent), elapsed_time)\n        new_state = trajectory(agent)[current_time(trajectory(agent))]\n        set_position!(agent, new_state[1])\n        set_velocity!(agent, new_state[2])\n    end\nend","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"With these funcitons we have specified the full environment behaviour, and the environment is now fully functional in RxEnvironments.jl.  We can create the environment with the RxEnvironment factory method:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"car_engine_power = 0.6\ncar_friction_coefficient = 0.5\ncar_mass = 2.0\ncar_target = 1.0\n\nenv = RxEnvironment(MountainCarEnvironment(landscape))\nagent = add!(\n            env,\n            MountainCarAgent(\n                MountainCarState(-0.5, 0.0, 0.0),\n                car_engine_power,\n                car_friction_coefficient,\n                car_mass,\n                car_target,\n            ),\n        )","category":"page"},{"location":"lib/example_mountaincar/#Discrete-time-Mountain-Car","page":"Example: Mountain Car","title":"Discrete-time Mountain Car","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Classical control theory mainly deals with discrete-time environments, and it is actually very easy to convert the environment dynamics we have written in RxEnvironments to also define a discrete environment. In general, we can implement the time_interval function:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"time_interval(env::YourEnvironment) = dt","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"for your choice of dt. For our mountain car environment, we can set the default timestep to 01 as follows:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"time_interval(env::MountainCarEnvironment) = 0.1","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"This will still utilize all environment dynamics we have written for the continuous case, but will create a discrete-time environment. In order to create a discrete-time environment, please make sure to include the discrete=true keyword argument for the RxEnvironment factory method:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"car_engine_power = 0.6\ncar_friction_coefficient = 0.5\ncar_mass = 2.0\ncar_target = 1.0\n\nenv = RxEnvironment(MountainCarEnvironment(landscape); is_discrete=true)\nagent = add!(\n            env,\n            MountainCarAgent(\n                MountainCarState(-0.5, 0.0, 0.0),\n                car_engine_power,\n                car_friction_coefficient,\n                car_mass,\n                car_target,\n            ),\n        )","category":"page"},{"location":"lib/example_mountaincar/#Animating-the-state-of-the-environment","page":"Example: Mountain Car","title":"Animating the state of the environment","text":"","category":"section"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"In order to animate the state of the environment, we have to install GLMakie.jl and implement the plot_state function for our environment.","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"using GLMakie\n\nfunction RxEnvironments.plot_state(ax, environment::MountainCarEnvironment)\n    x = range(-2.5, 2.5, 100)\n    y = environment.landscape.(x)\n    lines!(ax, x, y)\n    for agent in environment.actors\n        pos = position(agent)\n        scatter!(ax, pos, environment.landscape(pos))\n    end\nend","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"Now we can call:","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"animate_state(env)","category":"page"},{"location":"lib/example_mountaincar/","page":"Example: Mountain Car","title":"Example: Mountain Car","text":"on an existing RxEnvironment wrapping the MountainCarEnvironment and obtain a similar visualization: (Image: )","category":"page"}]
}
