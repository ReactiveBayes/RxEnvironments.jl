<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Design Philosophy · RxEnvironments.jl</title><meta name="title" content="Design Philosophy · RxEnvironments.jl"/><meta property="og:title" content="Design Philosophy · RxEnvironments.jl"/><meta property="twitter:title" content="Design Philosophy · RxEnvironments.jl"/><meta name="description" content="Documentation for RxEnvironments.jl."/><meta property="og:description" content="Documentation for RxEnvironments.jl."/><meta property="twitter:description" content="Documentation for RxEnvironments.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">RxEnvironments.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../example_mountaincar/">Example: Mountain Car</a></li><li><a class="tocitem" href="../advanced_usage/">Advanced Usage</a></li><li class="is-active"><a class="tocitem" href>Design Philosophy</a><ul class="internal"><li><a class="tocitem" href="#Agent-Environment-interaction"><span>Agent-Environment interaction</span></a></li><li><a class="tocitem" href="#Entities-and-Markov-Blankets"><span>Entities and Markov Blankets</span></a></li><li><a class="tocitem" href="#The-power-of-Markov-Blankets"><span>The power of Markov Blankets</span></a></li></ul></li><li><a class="tocitem" href="../api_reference/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Design Philosophy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Design Philosophy</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/biaslab/RxEnvironments.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/biaslab/RxEnvironments.jl/blob/main/docs/src/lib/philosophy.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="lib-design-philosophy"><a class="docs-heading-anchor" href="#lib-design-philosophy">Design Philosophy</a><a id="lib-design-philosophy-1"></a><a class="docs-heading-anchor-permalink" href="#lib-design-philosophy" title="Permalink"></a></h1><p><code>RxEnvironments</code> is designed with <a href="https://doi.org/10.1007/s00422-010-0364-z">Active Inference</a> in mind. The philosophy behind Active Inference is different from classical control or reinforcement learning, and may even seem confusing if one is well-versed in either control or reinforcement learning. However, as explained on this page, the Active Inference philosophy gives us many advantages by design, such as multi-agent environments, compositional environments and nested environments. This page aims to clarify the design principles of <code>RxEnvironments</code>. </p><h2 id="Agent-Environment-interaction"><a class="docs-heading-anchor" href="#Agent-Environment-interaction">Agent-Environment interaction</a><a id="Agent-Environment-interaction-1"></a><a class="docs-heading-anchor-permalink" href="#Agent-Environment-interaction" title="Permalink"></a></h2><p>Classical reinforcement learning literature often makes the explicit distinction between an agent and the environment in which it lives. The interaction between agents and environments flows through the <a href="https://en.wikipedia.org/wiki/Markov_blanket">Markov Blanket</a> of the agent; the agent emits actions and receives sensory observations. Similarly, the environment receives actions and emits observations to the agent. This symmetry of the Markov Blanket of both the agent and environment is crucial to notice: The actions of the agent are the observations of the environment, and vice versa. Consequently, one can argue that the environment is also an agent, which communicates to the agent through its Markov Blanket.</p><h2 id="Entities-and-Markov-Blankets"><a class="docs-heading-anchor" href="#Entities-and-Markov-Blankets">Entities and Markov Blankets</a><a id="Entities-and-Markov-Blankets-1"></a><a class="docs-heading-anchor-permalink" href="#Entities-and-Markov-Blankets" title="Permalink"></a></h2><p>The observation in the previous paragraph calls for an overarching term for both agents and environments. <code>RxEnvironments</code> realizes this with the <code>AbstractEntity</code> type. An entity is anything that has a Markov Blanket and can therefore communicate with other entities. Both agents and environments are <code>AbstractEntity</code>&#39;s under the hood. The difference is that an environment should implement the <code>update!</code> function to encode the state transition, whereas in agents this should be replaced by an inference process that selects an action to perform. We do not explicitly funnel rewards back from environments to agents, instead, agents should interpret the observations it receives and attach value to them instead.</p><h2 id="The-power-of-Markov-Blankets"><a class="docs-heading-anchor" href="#The-power-of-Markov-Blankets">The power of Markov Blankets</a><a id="The-power-of-Markov-Blankets-1"></a><a class="docs-heading-anchor-permalink" href="#The-power-of-Markov-Blankets" title="Permalink"></a></h2><p>All logic of <code>RxEnvironments</code> is written on the <code>Entity</code> level, this means that all logic holds for both agents and environments. For example: The fact that we support multi-agent environments also implies that an agent could emit actions to multiple environments as well, or that an agent can communicate with other agents in the same environment through its Markov Blanket. The concept of an <code>Entity</code> is what makes <code>RxEnvironments</code> so powerful and versatile. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../advanced_usage/">« Advanced Usage</a><a class="docs-footer-nextpage" href="../api_reference/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Thursday 4 April 2024 11:51">Thursday 4 April 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
